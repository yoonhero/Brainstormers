# 2023 R&E 프로젝트 선행 연구 공부 일지

## Prerequisits

-   Brain Activity to Image

    -   [x] Hyperrealistic neural decoding for reconstructing faces from fMRI activations via the GAN latent space
    -   [ ] Brain2Image: Converting Brain Signals into Images
    -   [ ] End-to-End Deep Image Reconstruction From Human Brain Activity
    -   [ ] ThoughtViz: Visualizing Human Thoughts Using Generative Adversarial Network
    -   [ ] Towards a Passive BCI to Induce Lucid Dream

-   Brain Signal Analysis

    -   [ ] 합성곱 신경망을 이용한 뇌파 해석 기법
    -   [ ] 연세대학교 뇌 관련 PPT
    -   [ ] A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition
    -   [ ] EEG emotion recognition using dynamical graph convolutional neural networks
    -   [ ] Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks 
  

- Vision
  - [ ] AlexNet
  - [ ] VGGNet
  - [ ] GoogLeNet
  - [ ] Fast R-CNN
  - [ ] Rethinking the Inception Architecture for Computer Vision (Inception-v2~3) (2016)
  - [ ] Deep Residual Learning for Image Recognition (ResNet) (2015)
  - [ ] YOLO
  - [ ] MobileNet
  - [ ] Mask R-CNN
  - [ ] Active Learning for CNN : A Core-set Approach (2018)
  - [ ] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks(EfficientNet) (2019)
  - [ ] Learning Loss for Active Learning (2019)
  -   [ ] Learning Deep Architectures for AI
  

-   Generative Model

    -   Text

        -   [ ] Attention Is All You Need (Transformer)
        -   [ ] Improving Language Understanding by Generative Pre-Training (GPT1)
        -   [ ] Language Models are Unsupervised Multitask Learners (GPT2)
        -   [ ] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (BERT)

    -   Caption

        -   [ ] All You May Need for VQA are Image Captions
        -   [ ] CLIP: Learning Transferable Visual Models From Natural Language

    -   Generative Models
        -   [ ] Pixel Recurrent Neural Networks (PixelRNN)

        - GAN
          -   [x] Generative Adversarial Nets (GAN)
          -   [x] Conditional GAN
          -   [x] Pix2Pix
          -   [x] Cycle GAN
          -   [ ] StarGAN
          -   [ ] Pixel2Style2Pixel
          -   [ ] DCGAN
          -   [ ] PGGAN
          -   [x] StyleGAN
          -   [ ] StyleGANv2
          -   [ ] SinGAN
          -   [ ] StyleCLIP
          -   [ ] Resolution Dependent GAN Interpolation for Controllable Image Synthesis Between Domains
          -   [ ] Analyzing and Improving the Image Quality of StyleGAN
          -   [ ] StyleGAN2 Distillation for Feed-forward Image Manipulation
          -   [ ] StyleCariGAN: Caricature Generation via StyleGAN Feature Map Modulation

        -   [x] Auto-Encoding Variational Bayes (VAE)
        -   [ ] Disentangling Variational Autoencoders
        -   [ ] U-Net: Convolutional Networks for Biomedical Image Segmentation

        -   [ ] Zero-Shot Text-to-Image Generation (DallE-1)
        -   [ ] Hierarchical Text-Conditional Image Generation with CLIP Latents (DallE-2)

        - Diffusion Model

            -   [ ] Denoising Diffusion Probabilistic Model (Diffusion Model)
            -   [ ] Diffusion Models Beat GANs on Image Synthesis (Advanced Diffusion Model)
            -   [ ] Imagic: Text-Based Real Image Editing with Diffusion Models

-   To Study Again
    -   [x] CNN
    -   [x] RNN
    -   [x] LSTM
    -   [x] Seq2Seq
    -   [x] Embedding
    -   [x] Regularization
    -   [x] Optimization
    -   [ ] CRN
