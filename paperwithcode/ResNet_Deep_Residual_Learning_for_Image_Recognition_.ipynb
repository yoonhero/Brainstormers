{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgWyw0ryUuogNO1jvCdjxr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonhero/Brainstormers/blob/master/paperwithcode/ResNet_Deep_Residual_Learning_for_Image_Recognition_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZzPyZegMsvQB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "iYJu6HvhtDST"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential() # if x identity\n",
        "\n",
        "        if stride != 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nm3WI9watIP_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1) # 처음 레이어에서만 w h 줄어들도록 \n",
        "        layers = []\n",
        "\n",
        "        for stride in strides: \n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "        "
      ],
      "metadata": {
        "id": "g9KWlz6gtpoi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "6Ze7RH-bvK5p"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = T.Compose([\n",
        "    T.RandomCrop(32, padding=4),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8NNm68JvUuK",
        "outputId": "db659293-d206-4042-c91d-e61fa0dda6f5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "net = ResNet18().to(device)\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
        "\n",
        "def train(epoch):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = net(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = pred.max(1)\n",
        "\n",
        "        total += x.size(0)\n",
        "        correct += predicted.eq(y).sum().item()\n",
        "\n",
        "    acc = correct / total\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch}] | Train Loss: {train_loss} | Accuracy : {acc}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ypQozgyewfKQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    if epoch >= 150:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "BXsMMUMPx8GB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    adjust_learning_rate(optimizer, epoch)   \n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRrPhfjfxtMW",
        "outputId": "a7433ce7-730e-4f01-c32f-d44cf6715255"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0] | Train Loss: 1.797032809318484 | Accuracy : 0.3444\n",
            "Epoch [1] | Train Loss: 1.3124886889896734 | Accuracy : 0.52248\n",
            "Epoch [2] | Train Loss: 1.041722156812468 | Accuracy : 0.6287\n",
            "Epoch [3] | Train Loss: 0.8740182008279864 | Accuracy : 0.69074\n",
            "Epoch [4] | Train Loss: 0.7367094144644335 | Accuracy : 0.73914\n",
            "Epoch [5] | Train Loss: 0.6396203605110383 | Accuracy : 0.77822\n",
            "Epoch [6] | Train Loss: 0.5618307292461395 | Accuracy : 0.8064\n",
            "Epoch [7] | Train Loss: 0.5019640300584876 | Accuracy : 0.82722\n",
            "Epoch [8] | Train Loss: 0.46653542806730247 | Accuracy : 0.83842\n",
            "Epoch [9] | Train Loss: 0.43487626878196933 | Accuracy : 0.84908\n",
            "Epoch [10] | Train Loss: 0.40719012020494016 | Accuracy : 0.85854\n",
            "Epoch [11] | Train Loss: 0.3782024359535378 | Accuracy : 0.86972\n",
            "Epoch [12] | Train Loss: 0.3594250238841147 | Accuracy : 0.877\n",
            "Epoch [13] | Train Loss: 0.3453153218226055 | Accuracy : 0.8813\n",
            "Epoch [14] | Train Loss: 0.3278406640833906 | Accuracy : 0.88656\n",
            "Epoch [15] | Train Loss: 0.31799167181219895 | Accuracy : 0.88976\n",
            "Epoch [16] | Train Loss: 0.3064730876242108 | Accuracy : 0.89454\n",
            "Epoch [17] | Train Loss: 0.2936857822720352 | Accuracy : 0.89972\n",
            "Epoch [18] | Train Loss: 0.28184155656782256 | Accuracy : 0.90264\n",
            "Epoch [19] | Train Loss: 0.2818551722847287 | Accuracy : 0.9047\n"
          ]
        }
      ]
    }
  ]
}