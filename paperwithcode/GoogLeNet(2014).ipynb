{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt8j0aJu8QyhxeLgnuObfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonhero/Brainstormers/blob/master/paperwithcode/GoogLeNet(2014).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x6ifmZGPu6p3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.aux_logits = aux_logits\n",
        "\n",
        "        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, 2, 1)\n",
        "        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, 2, 1)\n",
        "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, 2, 1)\n",
        "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(3, 2, 1)\n",
        "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "        self.avgpool = nn.AvgPool2d(7, 1)\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc1 = nn.Linear(1024, num_classes)\n",
        "\n",
        "        if self.aux_logits:\n",
        "            self.aux1 = InceptionAux(512, num_classes)\n",
        "            self.aux2 = InceptionAux(528, num_classes)\n",
        "        else:\n",
        "            self.aux1 = self.aux2 = None\n",
        "\n",
        "        # weight initialization\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.inception4a(x)\n",
        "\n",
        "        if self.aux_logits and self.training:\n",
        "            aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "\n",
        "        if self.aux_logits and self.training:\n",
        "            aux2 = self.aux2(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        if self.aux_logits and self.training:\n",
        "            return x, aux1, aux2\n",
        "        else:\n",
        "            return x \n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, **kwargs),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_layer(x)\n",
        "\n",
        "class Inception_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
        "        super().__init__()\n",
        "\n",
        "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, red_3x3, kernel_size=1),\n",
        "            conv_block(red_3x3, out_3x3, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, red_5x5, kernel_size=1),\n",
        "            conv_block(red_5x5, out_5x5, kernel_size=5, padding=2),\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            conv_block(in_channels, out_1x1pool, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            conv_block(in_channels, 128, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QfEawTZ_9Pem"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 3, 224, 224)\n",
        "model = GoogLeNet(aux_logits=True, num_classes=10, init_weights=True)\n",
        "output = model(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvDzwZcc_6P5",
        "outputId": "d05d2dca-524a-45f6-d7b0-beed94c8c075"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 0.0845, -0.0747,  0.0498,  0.1710,  0.0838,  0.0992,  0.1047, -0.0061,\n",
            "         -0.0110, -0.0180],\n",
            "        [ 0.1152, -0.2986,  0.2284,  0.0596,  0.0230,  0.1411,  0.1498, -0.2092,\n",
            "          0.2895,  0.1457],\n",
            "        [ 0.2199, -0.2631, -0.0484,  0.3480,  0.0636, -0.0117, -0.0631, -0.1843,\n",
            "          0.1765,  0.1026]], grad_fn=<AddmmBackward0>), tensor([[-0.2636, -0.0529, -0.0502, -0.0923,  0.1233, -0.0392,  0.0957, -0.0537,\n",
            "         -0.1397,  0.1802],\n",
            "        [-0.1534, -0.1977,  0.0508, -0.0378,  0.0881, -0.1347,  0.1292, -0.2795,\n",
            "         -0.0364, -0.0059],\n",
            "        [-0.1982, -0.0701,  0.0381,  0.1193, -0.1332, -0.0344, -0.0529,  0.0448,\n",
            "         -0.0615,  0.0595]], grad_fn=<AddmmBackward0>), tensor([[-0.0910,  0.0229, -0.0390,  0.0491,  0.0021, -0.0343, -0.1118,  0.2269,\n",
            "         -0.0371, -0.0250],\n",
            "        [-0.1038, -0.1098, -0.1612, -0.0224,  0.0803, -0.1053, -0.1266,  0.0072,\n",
            "          0.0340, -0.1520],\n",
            "        [-0.1390, -0.1998, -0.0795,  0.0529,  0.1091, -0.1418,  0.1469, -0.1549,\n",
            "          0.1187, -0.0031]], grad_fn=<AddmmBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3mZGVkqBfs6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}