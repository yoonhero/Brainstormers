{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, time_steps, input_size)\n",
    "inputs = torch.Tensor(1, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _status = cell(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell2 = nn.RNN(input_size=5, hidden_size=8, num_layers=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6083,  0.8355,  0.5708, -0.3716, -0.6623,  0.0996,  0.6121,\n",
       "           -0.0743],\n",
       "          [ 0.2737,  0.6355, -0.7876, -0.2314, -0.9372, -0.1862, -0.0123,\n",
       "           -0.6123],\n",
       "          [-0.3566,  0.1497, -0.6630, -0.1334, -0.9133, -0.5148, -0.2717,\n",
       "           -0.7654],\n",
       "          [-0.4782, -0.2609, -0.5360, -0.0553, -0.4896, -0.7279, -0.6158,\n",
       "           -0.7325],\n",
       "          [-0.4937, -0.3036, -0.4181, -0.2692, -0.3155, -0.7792, -0.6911,\n",
       "           -0.7297],\n",
       "          [-0.5752,  0.6833,  0.5831, -0.5291, -0.5507, -0.4296,  0.1549,\n",
       "           -0.2202],\n",
       "          [ 0.3819,  0.5586,  0.3087, -0.2447, -0.6286, -0.7265, -0.0984,\n",
       "           -0.7481],\n",
       "          [-0.4454,  0.0096, -0.4693,  0.0978, -0.1975, -0.5299, -0.3923,\n",
       "           -0.6518],\n",
       "          [-0.0729,  0.2983,  0.4924, -0.3129, -0.4276, -0.8786, -0.5339,\n",
       "           -0.7732],\n",
       "          [ 0.0525,  0.4244,  0.5140, -0.1780, -0.2375, -0.8388, -0.3839,\n",
       "           -0.7348]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
       "            1.0000]],\n",
       " \n",
       "         [[ 0.0525,  0.4244,  0.5140, -0.1780, -0.2375, -0.8388, -0.3839,\n",
       "           -0.7348]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"apple\"\n",
    "label_str = \"pple!\"\n",
    "\n",
    "char_vocab = sorted(list(set(input_str+label_str)))\n",
    "vocab_size = len(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size   \n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = {c:i for i, c in char_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [char_to_index[c] for c in input_str]\n",
    "y_data = [char_to_index[c] for c in label_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor(x_data)\n",
    "y_data = torch.tensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.unsqueeze(0)\n",
    "y_data = y_data.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YSH\\AppData\\Local\\Temp\\ipykernel_13776\\2348034151.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  X = torch.FloatTensor(x_one_hot)\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1., 0.],\n",
       "          [0., 0., 1., 0., 0.]]]),\n",
       " tensor([[4, 4, 3, 2, 0]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNNet, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNNNet(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2120, -0.5176, -0.3912,  0.1878, -0.4714],\n",
      "         [ 0.5138, -0.1719, -0.3396,  0.2266, -0.5027],\n",
      "         [ 0.4090, -0.2654, -0.2986,  0.1821, -0.4719],\n",
      "         [ 0.2919, -0.2962, -0.4312, -0.0753, -0.2817],\n",
      "         [ 0.4151, -0.2758, -0.2419,  0.0471, -0.4107]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100 | Loss: 1.7051255702972412 | Prediction: !!!!! \n",
      "1/100 | Loss: 1.419965147972107 | Prediction: !!!!! \n",
      "2/100 | Loss: 1.2154532670974731 | Prediction: pp!p! \n",
      "3/100 | Loss: 1.0496013164520264 | Prediction: pppe! \n",
      "4/100 | Loss: 0.8711943626403809 | Prediction: pppe! \n",
      "5/100 | Loss: 0.6606134176254272 | Prediction: pple! \n",
      "6/100 | Loss: 0.47183918952941895 | Prediction: pple! \n",
      "7/100 | Loss: 0.327343225479126 | Prediction: pple! \n",
      "8/100 | Loss: 0.225504070520401 | Prediction: pple! \n",
      "9/100 | Loss: 0.15435174107551575 | Prediction: pple! \n",
      "10/100 | Loss: 0.10624395310878754 | Prediction: pple! \n",
      "11/100 | Loss: 0.07466208934783936 | Prediction: pple! \n",
      "12/100 | Loss: 0.0536690354347229 | Prediction: pple! \n",
      "13/100 | Loss: 0.039234697818756104 | Prediction: pple! \n",
      "14/100 | Loss: 0.029060428962111473 | Prediction: pple! \n",
      "15/100 | Loss: 0.021828174591064453 | Prediction: pple! \n",
      "16/100 | Loss: 0.016677653416991234 | Prediction: pple! \n",
      "17/100 | Loss: 0.012990151531994343 | Prediction: pple! \n",
      "18/100 | Loss: 0.01031818799674511 | Prediction: pple! \n",
      "19/100 | Loss: 0.008349613286554813 | Prediction: pple! \n",
      "20/100 | Loss: 0.006872942205518484 | Prediction: pple! \n",
      "21/100 | Loss: 0.005746117793023586 | Prediction: pple! \n",
      "22/100 | Loss: 0.00487297959625721 | Prediction: pple! \n",
      "23/100 | Loss: 0.004187163896858692 | Prediction: pple! \n",
      "24/100 | Loss: 0.003641938092187047 | Prediction: pple! \n",
      "25/100 | Loss: 0.003203602507710457 | Prediction: pple! \n",
      "26/100 | Loss: 0.0028477220330387354 | Prediction: pple! \n",
      "27/100 | Loss: 0.002555887447670102 | Prediction: pple! \n",
      "28/100 | Loss: 0.0023145757149904966 | Prediction: pple! \n",
      "29/100 | Loss: 0.002113168593496084 | Prediction: pple! \n",
      "30/100 | Loss: 0.001943862298503518 | Prediction: pple! \n",
      "31/100 | Loss: 0.0018005107995122671 | Prediction: pple! \n",
      "32/100 | Loss: 0.0016782472375780344 | Prediction: pple! \n",
      "33/100 | Loss: 0.0015732236206531525 | Prediction: pple! \n",
      "34/100 | Loss: 0.0014825178077444434 | Prediction: pple! \n",
      "35/100 | Loss: 0.0014036583015695214 | Prediction: pple! \n",
      "36/100 | Loss: 0.0013348860666155815 | Prediction: pple! \n",
      "37/100 | Loss: 0.0012744894484058022 | Prediction: pple! \n",
      "38/100 | Loss: 0.0012212314177304506 | Prediction: pple! \n",
      "39/100 | Loss: 0.0011740898480638862 | Prediction: pple! \n",
      "40/100 | Loss: 0.0011321366764605045 | Prediction: pple! \n",
      "41/100 | Loss: 0.0010947060072794557 | Prediction: pple! \n",
      "42/100 | Loss: 0.0010611076140776277 | Prediction: pple! \n",
      "43/100 | Loss: 0.0010309848003089428 | Prediction: pple! \n",
      "44/100 | Loss: 0.0010037661995738745 | Prediction: pple! \n",
      "45/100 | Loss: 0.0009790953481569886 | Prediction: pple! \n",
      "46/100 | Loss: 0.0009567097877152264 | Prediction: pple! \n",
      "47/100 | Loss: 0.0009362766286358237 | Prediction: pple! \n",
      "48/100 | Loss: 0.0009176769526675344 | Prediction: pple! \n",
      "49/100 | Loss: 0.0009006011532619596 | Prediction: pple! \n",
      "50/100 | Loss: 0.0008849301375448704 | Prediction: pple! \n",
      "51/100 | Loss: 0.0008704260690137744 | Prediction: pple! \n",
      "52/100 | Loss: 0.0008570648496970534 | Prediction: pple! \n",
      "53/100 | Loss: 0.0008446561405435205 | Prediction: pple! \n",
      "54/100 | Loss: 0.0008331524441018701 | Prediction: pple! \n",
      "55/100 | Loss: 0.000822458416223526 | Prediction: pple! \n",
      "56/100 | Loss: 0.0008123835432343185 | Prediction: pple! \n",
      "57/100 | Loss: 0.0008029992459341884 | Prediction: pple! \n",
      "58/100 | Loss: 0.0007941866060718894 | Prediction: pple! \n",
      "59/100 | Loss: 0.0007859217002987862 | Prediction: pple! \n",
      "60/100 | Loss: 0.0007780377636663616 | Prediction: pple! \n",
      "61/100 | Loss: 0.0007705587195232511 | Prediction: pple! \n",
      "62/100 | Loss: 0.0007635321817360818 | Prediction: pple! \n",
      "63/100 | Loss: 0.0007568629225715995 | Prediction: pple! \n",
      "64/100 | Loss: 0.0007504317327402532 | Prediction: pple! \n",
      "65/100 | Loss: 0.0007443102658726275 | Prediction: pple! \n",
      "66/100 | Loss: 0.0007384506752714515 | Prediction: pple! \n",
      "67/100 | Loss: 0.0007328531355597079 | Prediction: pple! \n",
      "68/100 | Loss: 0.0007273984374478459 | Prediction: pple! \n",
      "69/100 | Loss: 0.0007221581181511283 | Prediction: pple! \n",
      "70/100 | Loss: 0.0007171559263952076 | Prediction: pple! \n",
      "71/100 | Loss: 0.0007122490205802023 | Prediction: pple! \n",
      "72/100 | Loss: 0.0007075088215060532 | Prediction: pple! \n",
      "73/100 | Loss: 0.0007028638501651585 | Prediction: pple! \n",
      "74/100 | Loss: 0.0006984332576394081 | Prediction: pple! \n",
      "75/100 | Loss: 0.0006940503371879458 | Prediction: pple! \n",
      "76/100 | Loss: 0.0006898340652696788 | Prediction: pple! \n",
      "77/100 | Loss: 0.0006856177351437509 | Prediction: pple! \n",
      "78/100 | Loss: 0.0006815444212406874 | Prediction: pple! \n",
      "79/100 | Loss: 0.0006776139489375055 | Prediction: pple! \n",
      "80/100 | Loss: 0.0006736597279086709 | Prediction: pple! \n",
      "81/100 | Loss: 0.0006697530043311417 | Prediction: pple! \n",
      "82/100 | Loss: 0.0006660131039097905 | Prediction: pple! \n",
      "83/100 | Loss: 0.0006622730870731175 | Prediction: pple! \n",
      "84/100 | Loss: 0.0006585806841030717 | Prediction: pple! \n",
      "85/100 | Loss: 0.0006549836834892631 | Prediction: pple! \n",
      "86/100 | Loss: 0.0006514579872600734 | Prediction: pple! \n",
      "87/100 | Loss: 0.0006478370632976294 | Prediction: pple! \n",
      "88/100 | Loss: 0.0006444543832913041 | Prediction: pple! \n",
      "89/100 | Loss: 0.0006410239730030298 | Prediction: pple! \n",
      "90/100 | Loss: 0.0006375935627147555 | Prediction: pple! \n",
      "91/100 | Loss: 0.0006342345150187612 | Prediction: pple! \n",
      "92/100 | Loss: 0.0006309231976047158 | Prediction: pple! \n",
      "93/100 | Loss: 0.0006276356289163232 | Prediction: pple! \n",
      "94/100 | Loss: 0.0006243957905098796 | Prediction: pple! \n",
      "95/100 | Loss: 0.0006211797008290887 | Prediction: pple! \n",
      "96/100 | Loss: 0.0006179636111482978 | Prediction: pple! \n",
      "97/100 | Loss: 0.0006148427492007613 | Prediction: pple! \n",
      "98/100 | Loss: 0.0006116504082456231 | Prediction: pple! \n",
      "99/100 | Loss: 0.0006085533532314003 | Prediction: pple! \n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs.view(-1, input_size), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result = outputs.data.numpy().argmax(axis=2)\n",
    "    result_str = \"\".join([index_to_char[c] for c in np.squeeze(result)])\n",
    "    print(f\"{i}/100 | Loss: {loss.item()} | Prediction: {result_str} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
