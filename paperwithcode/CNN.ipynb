{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 13, 28, 27, 18])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.convolve((1, 2, 3), (4, 5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.random.random(100000)\n",
    "arr2 = np.random.random(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937 ms ± 132 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.convolve(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.88 ms ± 83.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "scipy.signal.fftconvolve(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5, stride=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4000, 50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"연산 전\", x.size())\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"conv1 연산 후\", x.size())\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(\"conv2 연산 후\", x.size()) \n",
    "\n",
    "        x = self.flatten(x)\n",
    "        #print(\"차원 감소 후\", x.size())\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"fc1 연산 후\", x.size())\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        #print(\"fc2 연산 후\", x.size())\n",
    "\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "output = cnn(torch.randn(10, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, ), (1.0, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = \"./MNIST_DATASET\"\n",
    "\n",
    "train_dataset = MNIST(download_root, transform =mnist_transform, train=True, download=True)\n",
    "test_dataset = MNIST(download_root, transform =mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device )\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/5] Loss: 0.22831517457962036\n",
      "Epoch: [1/5] Loss: 0.07873327285051346\n",
      "Epoch: [2/5] Loss: 0.055560093373060226\n",
      "Epoch: [3/5] Loss: 0.04382827877998352\n",
      "Epoch: [4/5] Loss: 0.034306298941373825\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    for i, (img_data, label_data) in enumerate(train_loader):\n",
    "        img_data, label_data = img_data.to(device), label_data.to(device)\n",
    "\n",
    "        pred = model(img_data)\n",
    "\n",
    "        loss = loss_function(pred, label_data)\n",
    "        avg_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss /= len(train_loader)\n",
    "    print(f\"Epoch: [{epoch}/{epochs}] Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        correct /= size \n",
    "        print(f\"Test Error: \\nAccuracy: {(100*correct):>0.1f}%, Avg Loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      "Accuracy: 98.4%, Avg Loss: 0.049440 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_loader, model, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.keep_prob = 0.5\n",
    "\n",
    "        # L1 ImgIN shape = (?, 28, 28, 1)\n",
    "        #    Conv       -> (?, 28, 28, 32)\n",
    "        #    Pool       -> (?, 14, 14, 32)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # L4 Fc 4*4*128 inputs -> 623 outputs\n",
    "        self.fc1 = nn.Linear(4*4*128, 625, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            self.fc1, \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=1-self.keep_prob)\n",
    "        )\n",
    "\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = nn.Linear(625, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNv2().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.171949297\n",
      "[Epoch:    2] cost = 0.0464844778\n",
      "[Epoch:    3] cost = 0.0343767591\n",
      "[Epoch:    4] cost = 0.0261751544\n",
      "[Epoch:    5] cost = 0.0221783482\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      "Accuracy: 99.3%, Avg Loss: 0.025699 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_loader, model, criterion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 더 깊은 Convolution Network 의 정확도가 더 높은 것을 확인할 수 있었다. \n",
    "\n",
    "**깊은 컨볼루션 네트워크**\n",
    "\n",
    "Test Error: \n",
    "Accuracy: 99.3%, Avg Loss: 0.025699 \n",
    "\n",
    "**간단한 컨볼루션 네트워크**\n",
    "\n",
    "Test Error: \n",
    "Accuracy: 98.4%, Avg Loss: 0.049440 \n",
    "\n",
    "깊고 효율적으로 네트워크를 쌓는다면 간단한 네트워크보다 월등한 성능을 낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
